{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Define EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "                               restore_best_weights=True)  # Restores model to best weights with the lowest validation loss\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n",
        "                epochs=100,  # Set a high number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[early_stopping])  # Add the early stopping callback"
      ],
      "metadata": {
        "id": "1lkRG_4naVO_",
        "outputId": "60bd4deb-0c12-4ede-9d40-cdd7a29395b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.4344 - val_loss: 0.2346\n",
            "Epoch 2/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2299 - val_loss: 0.2090\n",
            "Epoch 3/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.2032 - val_loss: 0.1852\n",
            "Epoch 4/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1840 - val_loss: 0.1765\n",
            "Epoch 5/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1764 - val_loss: 0.1709\n",
            "Epoch 6/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1713 - val_loss: 0.1685\n",
            "Epoch 7/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1690 - val_loss: 0.1657\n",
            "Epoch 8/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1665 - val_loss: 0.1636\n",
            "Epoch 9/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1643 - val_loss: 0.1612\n",
            "Epoch 10/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1615 - val_loss: 0.1584\n",
            "Epoch 11/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1590 - val_loss: 0.1559\n",
            "Epoch 12/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1568 - val_loss: 0.1540\n",
            "Epoch 13/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1549 - val_loss: 0.1525\n",
            "Epoch 14/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1529 - val_loss: 0.1511\n",
            "Epoch 15/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1519 - val_loss: 0.1500\n",
            "Epoch 16/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1511 - val_loss: 0.1493\n",
            "Epoch 17/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1499 - val_loss: 0.1484\n",
            "Epoch 18/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1493 - val_loss: 0.1478\n",
            "Epoch 19/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1492 - val_loss: 0.1473\n",
            "Epoch 20/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1483 - val_loss: 0.1467\n",
            "Epoch 21/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1478 - val_loss: 0.1454\n",
            "Epoch 22/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1464 - val_loss: 0.1445\n",
            "Epoch 23/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1453 - val_loss: 0.1435\n",
            "Epoch 24/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1445 - val_loss: 0.1428\n",
            "Epoch 25/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1442 - val_loss: 0.1423\n",
            "Epoch 26/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1431 - val_loss: 0.1417\n",
            "Epoch 27/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1429 - val_loss: 0.1409\n",
            "Epoch 28/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1422 - val_loss: 0.1403\n",
            "Epoch 29/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1415 - val_loss: 0.1398\n",
            "Epoch 30/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1409 - val_loss: 0.1393\n",
            "Epoch 31/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1404 - val_loss: 0.1390\n",
            "Epoch 32/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1405 - val_loss: 0.1388\n",
            "Epoch 33/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1405 - val_loss: 0.1388\n",
            "Epoch 34/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1402 - val_loss: 0.1384\n",
            "Epoch 35/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1396 - val_loss: 0.1383\n",
            "Epoch 36/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1399 - val_loss: 0.1382\n",
            "Epoch 37/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1399 - val_loss: 0.1381\n",
            "Epoch 38/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1394 - val_loss: 0.1380\n",
            "Epoch 39/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1394 - val_loss: 0.1378\n",
            "Epoch 40/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1391 - val_loss: 0.1380\n",
            "Epoch 41/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1392 - val_loss: 0.1377\n",
            "Epoch 42/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1393 - val_loss: 0.1377\n",
            "Epoch 43/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1394 - val_loss: 0.1377\n",
            "Epoch 44/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1390 - val_loss: 0.1377\n",
            "Epoch 45/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1394 - val_loss: 0.1376\n",
            "Epoch 46/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1388 - val_loss: 0.1375\n",
            "Epoch 47/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1389 - val_loss: 0.1374\n",
            "Epoch 48/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1389 - val_loss: 0.1374\n",
            "Epoch 49/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1387 - val_loss: 0.1374\n",
            "Epoch 50/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1389 - val_loss: 0.1374\n",
            "Epoch 51/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1390 - val_loss: 0.1373\n",
            "Epoch 52/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1391 - val_loss: 0.1374\n",
            "Epoch 53/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1390 - val_loss: 0.1374\n",
            "Epoch 54/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1388 - val_loss: 0.1373\n",
            "Epoch 55/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1389 - val_loss: 0.1373\n",
            "Epoch 56/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1388 - val_loss: 0.1374\n",
            "Epoch 57/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1388 - val_loss: 0.1372\n",
            "Epoch 58/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1389 - val_loss: 0.1371\n",
            "Epoch 59/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1387 - val_loss: 0.1372\n",
            "Epoch 60/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1389 - val_loss: 0.1371\n",
            "Epoch 61/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1388 - val_loss: 0.1370\n",
            "Epoch 62/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1388 - val_loss: 0.1371\n",
            "Epoch 63/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1387 - val_loss: 0.1371\n",
            "Epoch 64/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1386 - val_loss: 0.1372\n",
            "Epoch 65/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1386 - val_loss: 0.1371\n",
            "Epoch 66/100\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1387 - val_loss: 0.1372\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cbaeeb536d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import TerminateOnNaN\n",
        "\n",
        "# Define the TerminateOnNaN callback\n",
        "terminate_on_nan = TerminateOnNaN()\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "# Assuming x_train and x_test are your training and validation datasets\n",
        "autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n",
        "                epochs=30,  # Set the number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[terminate_on_nan])  # Add the TerminateOnNaN callback"
      ],
      "metadata": {
        "id": "uHepEk2xbGej",
        "outputId": "483b7e35-aded-4156-890d-782aaeb78f32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.4361 - val_loss: 0.2379\n",
            "Epoch 2/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2309 - val_loss: 0.2058\n",
            "Epoch 3/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2039 - val_loss: 0.1912\n",
            "Epoch 4/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1907 - val_loss: 0.1818\n",
            "Epoch 5/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1805 - val_loss: 0.1697\n",
            "Epoch 6/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1688 - val_loss: 0.1615\n",
            "Epoch 7/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1618 - val_loss: 0.1564\n",
            "Epoch 8/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1564 - val_loss: 0.1521\n",
            "Epoch 9/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.1528 - val_loss: 0.1505\n",
            "Epoch 10/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1510 - val_loss: 0.1491\n",
            "Epoch 11/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1500 - val_loss: 0.1483\n",
            "Epoch 12/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.1497 - val_loss: 0.1476\n",
            "Epoch 13/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1489 - val_loss: 0.1473\n",
            "Epoch 14/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1486 - val_loss: 0.1466\n",
            "Epoch 15/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1480 - val_loss: 0.1463\n",
            "Epoch 16/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1473 - val_loss: 0.1460\n",
            "Epoch 17/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1472 - val_loss: 0.1455\n",
            "Epoch 18/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1463 - val_loss: 0.1448\n",
            "Epoch 19/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1460 - val_loss: 0.1440\n",
            "Epoch 20/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1452 - val_loss: 0.1433\n",
            "Epoch 21/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1448 - val_loss: 0.1426\n",
            "Epoch 22/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1441 - val_loss: 0.1421\n",
            "Epoch 23/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1434 - val_loss: 0.1419\n",
            "Epoch 24/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1434 - val_loss: 0.1416\n",
            "Epoch 25/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1430 - val_loss: 0.1415\n",
            "Epoch 26/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1429 - val_loss: 0.1413\n",
            "Epoch 27/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1424 - val_loss: 0.1412\n",
            "Epoch 28/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1423 - val_loss: 0.1410\n",
            "Epoch 29/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1421 - val_loss: 0.1409\n",
            "Epoch 30/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1420 - val_loss: 0.1408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7df762287640>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='autoencoder_best.keras',  # File path to save the model\n",
        "                             monitor='val_loss',  # Metric to monitor\n",
        "                             save_best_only=True,  # Save only the best model (based on the monitored metric)\n",
        "                             mode='min',  # Minimize the monitored metric (e.g., validation loss)\n",
        "                             save_weights_only=False,  # Save the entire model (set to True to save only weights)\n",
        "                             verbose=1)  # Print a message when saving the model\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "# Assuming x_train and x_test are your training and validation datasets\n",
        "autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n",
        "                epochs=30,  # Number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),  # Validation data\n",
        "                callbacks=[checkpoint])  # Add the ModelCheckpoint callback"
      ],
      "metadata": {
        "id": "icqItLhtbNyc",
        "outputId": "201a17ac-af30-455a-d26c-1e696b656552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4266\n",
            "Epoch 1: val_loss improved from inf to 0.23872, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.4252 - val_loss: 0.2387\n",
            "Epoch 2/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2274\n",
            "Epoch 2: val_loss improved from 0.23872 to 0.19719, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2271 - val_loss: 0.1972\n",
            "Epoch 3/30\n",
            "\u001b[1m228/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1912\n",
            "Epoch 3: val_loss improved from 0.19719 to 0.17481, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1910 - val_loss: 0.1748\n",
            "Epoch 4/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1748\n",
            "Epoch 4: val_loss improved from 0.17481 to 0.16954, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1748 - val_loss: 0.1695\n",
            "Epoch 5/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1692\n",
            "Epoch 5: val_loss improved from 0.16954 to 0.16123, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1691 - val_loss: 0.1612\n",
            "Epoch 6/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1615\n",
            "Epoch 6: val_loss improved from 0.16123 to 0.15663, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1614 - val_loss: 0.1566\n",
            "Epoch 7/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1579\n",
            "Epoch 7: val_loss improved from 0.15663 to 0.15490, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1579 - val_loss: 0.1549\n",
            "Epoch 8/30\n",
            "\u001b[1m228/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1561\n",
            "Epoch 8: val_loss improved from 0.15490 to 0.15396, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1561 - val_loss: 0.1540\n",
            "Epoch 9/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1552\n",
            "Epoch 9: val_loss improved from 0.15396 to 0.15342, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1552 - val_loss: 0.1534\n",
            "Epoch 10/30\n",
            "\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1547\n",
            "Epoch 10: val_loss improved from 0.15342 to 0.15280, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1547 - val_loss: 0.1528\n",
            "Epoch 11/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1541\n",
            "Epoch 11: val_loss improved from 0.15280 to 0.15223, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1541 - val_loss: 0.1522\n",
            "Epoch 12/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1535\n",
            "Epoch 12: val_loss improved from 0.15223 to 0.15167, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1535 - val_loss: 0.1517\n",
            "Epoch 13/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1533\n",
            "Epoch 13: val_loss improved from 0.15167 to 0.15072, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1533 - val_loss: 0.1507\n",
            "Epoch 14/30\n",
            "\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1522\n",
            "Epoch 14: val_loss improved from 0.15072 to 0.15011, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1522 - val_loss: 0.1501\n",
            "Epoch 15/30\n",
            "\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1514\n",
            "Epoch 15: val_loss improved from 0.15011 to 0.14921, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1514 - val_loss: 0.1492\n",
            "Epoch 16/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1509\n",
            "Epoch 16: val_loss improved from 0.14921 to 0.14856, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1509 - val_loss: 0.1486\n",
            "Epoch 17/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1497\n",
            "Epoch 17: val_loss improved from 0.14856 to 0.14777, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1497 - val_loss: 0.1478\n",
            "Epoch 18/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1487\n",
            "Epoch 18: val_loss improved from 0.14777 to 0.14735, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1487 - val_loss: 0.1473\n",
            "Epoch 19/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1488\n",
            "Epoch 19: val_loss improved from 0.14735 to 0.14669, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1488 - val_loss: 0.1467\n",
            "Epoch 20/30\n",
            "\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1482\n",
            "Epoch 20: val_loss improved from 0.14669 to 0.14636, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1482 - val_loss: 0.1464\n",
            "Epoch 21/30\n",
            "\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1478\n",
            "Epoch 21: val_loss improved from 0.14636 to 0.14574, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1478 - val_loss: 0.1457\n",
            "Epoch 22/30\n",
            "\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1468\n",
            "Epoch 22: val_loss improved from 0.14574 to 0.14538, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1468 - val_loss: 0.1454\n",
            "Epoch 23/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1463\n",
            "Epoch 23: val_loss improved from 0.14538 to 0.14441, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1463 - val_loss: 0.1444\n",
            "Epoch 24/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1455\n",
            "Epoch 24: val_loss improved from 0.14441 to 0.14363, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1455 - val_loss: 0.1436\n",
            "Epoch 25/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1448\n",
            "Epoch 25: val_loss improved from 0.14363 to 0.14285, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1448 - val_loss: 0.1429\n",
            "Epoch 26/30\n",
            "\u001b[1m228/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1439\n",
            "Epoch 26: val_loss improved from 0.14285 to 0.14240, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1439 - val_loss: 0.1424\n",
            "Epoch 27/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1436\n",
            "Epoch 27: val_loss improved from 0.14240 to 0.14187, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1436 - val_loss: 0.1419\n",
            "Epoch 28/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1432\n",
            "Epoch 28: val_loss improved from 0.14187 to 0.14148, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1432 - val_loss: 0.1415\n",
            "Epoch 29/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1429\n",
            "Epoch 29: val_loss improved from 0.14148 to 0.14118, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1429 - val_loss: 0.1412\n",
            "Epoch 30/30\n",
            "\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1425\n",
            "Epoch 30: val_loss improved from 0.14118 to 0.14081, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1425 - val_loss: 0.1408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cbadd270c40>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Define the ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',  # Metric to monitor\n",
        "                              factor=0.5,  # Factor by which the learning rate will be reduced (new_lr = lr * factor)\n",
        "                              patience=3,  # Number of epochs with no improvement after which learning rate will be reduced\n",
        "                              min_lr=1e-6,  # Lower bound for the learning rate\n",
        "                              verbose=1)  # Print message when the learning rate is reduced\n",
        "\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "# Assuming x_train and x_test are your training and validation datasets\n",
        "autoencoder.fit(x_train, x_train,  # For autoencoders, input and output are the same\n",
        "                epochs=30,  # Number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),  # Validation data\n",
        "                callbacks=[reduce_lr])  # Add the ReduceLROnPlateau callback"
      ],
      "metadata": {
        "id": "oprSe6g8bSAV",
        "outputId": "0db575b9-2b69-4dda-9246-c1ffe938fcb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.4341 - val_loss: 0.2389 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2272 - val_loss: 0.1941 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1900 - val_loss: 0.1770 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1763 - val_loss: 0.1686 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1678 - val_loss: 0.1605 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1609 - val_loss: 0.1562 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1570 - val_loss: 0.1531 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1537 - val_loss: 0.1490 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1498 - val_loss: 0.1463 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1474 - val_loss: 0.1445 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1457 - val_loss: 0.1435 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1447 - val_loss: 0.1426 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1443 - val_loss: 0.1421 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1432 - val_loss: 0.1414 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1428 - val_loss: 0.1411 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1424 - val_loss: 0.1407 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1425 - val_loss: 0.1402 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1415 - val_loss: 0.1398 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1414 - val_loss: 0.1393 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1406 - val_loss: 0.1386 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1400 - val_loss: 0.1377 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1389 - val_loss: 0.1369 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1380 - val_loss: 0.1357 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1370 - val_loss: 0.1351 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1362 - val_loss: 0.1345 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1354 - val_loss: 0.1339 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1352 - val_loss: 0.1334 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1349 - val_loss: 0.1330 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1347 - val_loss: 0.1328 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1339 - val_loss: 0.1325 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cbade30a530>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TerminateOnNaN, ReduceLROnPlateau\n",
        "\n",
        "# EarlyStopping callback to stop training if validation loss stops improving\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# ModelCheckpoint callback to save the best model based on validation loss\n",
        "checkpoint = ModelCheckpoint(filepath='autoencoder_best.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# TerminateOnNaN callback to stop training if the loss becomes NaN\n",
        "terminate_on_nan = TerminateOnNaN()\n",
        "\n",
        "# Define the ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,   patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images for the autoencoder\n",
        "x_train = x_train.reshape((len(x_train), -1))  # -1 infers the remaining dimension\n",
        "x_test = x_test.reshape((len(x_test), -1))  # -1 infers the remain\n",
        "\n",
        "# Define the dimensions of the input and the encoded representation\n",
        "input_dim = x_train.shape[1]\n",
        "encoding_dim = 16  # Compress to 16 features\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "# Define the encoder\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "# Adding a layer\n",
        "encoded1 = Dense(encoding_dim, activation='relu')(encoded)\n",
        "\n",
        "# Adding a layer\n",
        "decoded1 = Dense(encoding_dim, activation='relu')(encoded1)\n",
        "# Define the decoder\n",
        "decoded = Dense(input_dim, activation='sigmoid')(decoded1)\n",
        "\n",
        "# Combine the encoder and decoder into an autoencoder model\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Training with multiple callbacks\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=30,  # You can set a high number of epochs\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[reduce_lr, early_stopping, checkpoint, terminate_on_nan])  # Using multiple callbacks"
      ],
      "metadata": {
        "id": "aN1vwroXbWOu",
        "outputId": "33d527df-2039-4ea7-ec75-18b0ba0f1fc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4351\n",
            "Epoch 1: val_loss improved from inf to 0.24041, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.4326 - val_loss: 0.2404 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2276\n",
            "Epoch 2: val_loss improved from 0.24041 to 0.19593, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2273 - val_loss: 0.1959 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1929\n",
            "Epoch 3: val_loss improved from 0.19593 to 0.17989, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1928 - val_loss: 0.1799 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1789\n",
            "Epoch 4: val_loss improved from 0.17989 to 0.17106, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1789 - val_loss: 0.1711 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1718\n",
            "Epoch 5: val_loss improved from 0.17106 to 0.16711, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.1718 - val_loss: 0.1671 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1671\n",
            "Epoch 6: val_loss improved from 0.16711 to 0.16245, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1671 - val_loss: 0.1624 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1634\n",
            "Epoch 7: val_loss improved from 0.16245 to 0.16046, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1634 - val_loss: 0.1605 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1616\n",
            "Epoch 8: val_loss improved from 0.16046 to 0.15806, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1616 - val_loss: 0.1581 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1589\n",
            "Epoch 9: val_loss improved from 0.15806 to 0.15598, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1589 - val_loss: 0.1560 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1571\n",
            "Epoch 10: val_loss improved from 0.15598 to 0.15471, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1571 - val_loss: 0.1547 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1562\n",
            "Epoch 11: val_loss improved from 0.15471 to 0.15393, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1562 - val_loss: 0.1539 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m230/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1552\n",
            "Epoch 12: val_loss improved from 0.15393 to 0.15324, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1552 - val_loss: 0.1532 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1542\n",
            "Epoch 13: val_loss improved from 0.15324 to 0.15168, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1542 - val_loss: 0.1517 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1526\n",
            "Epoch 14: val_loss improved from 0.15168 to 0.14996, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1525 - val_loss: 0.1500 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1507\n",
            "Epoch 15: val_loss improved from 0.14996 to 0.14812, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1507 - val_loss: 0.1481 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1489\n",
            "Epoch 16: val_loss improved from 0.14812 to 0.14642, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1489 - val_loss: 0.1464 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1475\n",
            "Epoch 17: val_loss improved from 0.14642 to 0.14318, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1475 - val_loss: 0.1432 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1440\n",
            "Epoch 18: val_loss improved from 0.14318 to 0.14065, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1440 - val_loss: 0.1407 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m228/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1415\n",
            "Epoch 19: val_loss improved from 0.14065 to 0.13904, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1415 - val_loss: 0.1390 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1404\n",
            "Epoch 20: val_loss improved from 0.13904 to 0.13841, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1404 - val_loss: 0.1384 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1398\n",
            "Epoch 21: val_loss improved from 0.13841 to 0.13792, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1398 - val_loss: 0.1379 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1393\n",
            "Epoch 22: val_loss improved from 0.13792 to 0.13733, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1393 - val_loss: 0.1373 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1389\n",
            "Epoch 23: val_loss improved from 0.13733 to 0.13716, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.1389 - val_loss: 0.1372 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m232/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1386\n",
            "Epoch 24: val_loss improved from 0.13716 to 0.13706, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1386 - val_loss: 0.1371 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m229/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1381\n",
            "Epoch 25: val_loss improved from 0.13706 to 0.13654, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1381 - val_loss: 0.1365 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m231/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1376\n",
            "Epoch 26: val_loss improved from 0.13654 to 0.13637, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1377 - val_loss: 0.1364 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1375\n",
            "Epoch 27: val_loss improved from 0.13637 to 0.13590, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1375 - val_loss: 0.1359 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m234/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1374\n",
            "Epoch 28: val_loss did not improve from 0.13590\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1374 - val_loss: 0.1359 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1372\n",
            "Epoch 29: val_loss improved from 0.13590 to 0.13543, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1372 - val_loss: 0.1354 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m233/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1370\n",
            "Epoch 30: val_loss improved from 0.13543 to 0.13522, saving model to autoencoder_best.keras\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1370 - val_loss: 0.1352 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cbade1dcd00>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the entire model\n",
        "best_autoencoder = load_model('autoencoder_best.keras')\n",
        "\n",
        "# Let's look at the encoded representations\n",
        "encoded_data = best_autoencoder.predict(x_test)\n",
        "print(encoded_data)\n",
        "print(encoded_data.shape)"
      ],
      "metadata": {
        "id": "sbZy5UOQbhAV",
        "outputId": "e9e727bf-1321-4626-9b8c-3906cbb62565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "[[1.9807577e-15 1.5152339e-14 3.9891061e-13 ... 7.5100016e-15\n",
            "  6.1764503e-15 2.0991466e-16]\n",
            " [1.0935202e-10 4.1839920e-10 2.3050595e-10 ... 1.8456821e-10\n",
            "  2.4213373e-10 2.5670152e-10]\n",
            " [1.9581055e-16 1.8931988e-14 5.0116181e-16 ... 3.8398740e-16\n",
            "  8.2408886e-15 2.9677345e-15]\n",
            " ...\n",
            " [9.4068260e-16 6.2475350e-16 3.9129981e-14 ... 9.5997547e-15\n",
            "  1.2012526e-15 2.2314454e-17]\n",
            " [2.7297345e-10 8.1712576e-10 3.1884095e-09 ... 1.1436131e-09\n",
            "  4.0451742e-10 3.5425576e-11]\n",
            " [6.7035170e-14 3.0569222e-15 1.2275606e-14 ... 1.4145321e-13\n",
            "  1.8933355e-15 2.8076197e-15]]\n",
            "(10000, 784)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}